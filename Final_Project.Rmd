---
title: "Final_Project"
author: "Tessa Danehy, Josh Eiland, Chirag Kulkarni"
date: "11/17/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
#install.packages("naniar")
#install.packages("finalfit")
library(finalfit)
library(naniar)
library(caret)
require(randomForest)
data = read.csv("train.csv")
```

Since we are getting the data from the NFL Big Data Bowl competition, the database is pretty robust. After creating a missing values map (below), we can see that most of the information is complete, with the exception of weather data. 

Temperature (and to a lesser extent humidity) information seems to be missing at various points throughout the data. This is curious as there is weather data out there and we could likely find a way to populate those fields knowing the day and location of the game. We may first see how significant temperature is in predicting rush yardage to determine if completing the temp data is worth it. 

Following this, we looked at a summary of the data to determine 1) whether the data was in the right format and 2) if there were any unreasonable values. Again, the data from the NFL is pretty great so all the data came in the correct format (categoricals for team name, player name, location, etc). There are a few features that we may engineer though: age of player (from birth day) and minutes into game (from game clock). 

For some next steps, we want to take a look at each of the column variables critically and determine which we want to test in a potential model. Ultimately, we will be experimenting with many different variables but we may rule some out from the offset. After that, we would like to connect to a database (NFL API) to get player stats and/or rankings. There is data out there such as Average Yards Per Play for each player and that could certainly improve our model. 

```{r Assessing the data}
missing_plot(data)
# many of the values had empty strings instead of NAs, so we assigned them as NAs and ran missingness plot again 
data[data=='']=NA
missing_plot(data)

summary(data)
```


```{r Cleaning the Data}
# removing all players that are not the rusher, and then removing columns with variables we deem unimportant
df <- filter(data, data$NflId==data$NflIdRusher) %>% select(-c(JerseyNumber,Stadium,Location))
names(df)

# used the summary() or levels() function on each variable to get a sense of strange values or variables that may be useful. Code omitted for simplicity 
# conclusions: offence personnel and defense personnel are very helpful, we should turn them into multiple categories

summary(df$WindSpeed)
levels(df$WindDirection)
sum(is.na(df$WindSpeed))
summary(df$WindSpeed)

# look into:
# possession team- there are 33 values
# field position 34 values plus an empty ""
# offence formation has 10 values with an empty ""
# do we want player height to be a category or numerical? Rn is a category but I think numerical
# position has like 30 abbreviations and idk what they are
# clean stadium type, turf, GameWeather
# temp, humidity has tons of NAs
# remove wind speed? doesnt make sense 

# useful variables:
# offence personnel and defense personnel are very helpful
# should determine age from player birth date 

```


```{r reCat}

# Recategorizing the yardage to one of four categories
df$Cat <- "-"
# Negative plays
df[df$Yards < 0, which(colnames(df)=="Cat")] <- "Negative"
# Positive plays of less than 4 yards
df[df$Yards >= 0 & df$Yards < 4, which(colnames(df)=="Cat")] <- "Small"
# Plays of at least 4 but less than 10 yards
# This is the rate necessary to never face a 4th down
df[df$Yards >= 4 & df$Yards < 10, which(colnames(df)=="Cat")] <- "Medium"
# Plays gaining 10 or more yards - enough for a first down
   # (assuming no prior negative yardage since the last first down)
df[df$Yards >= 10, which(colnames(df)=="Cat")] <- "Large"
table(df$Cat)

short <- df[1:1000,]
setwd("C:/Users/jhe5a/OneDrive/Desktop/dsfinal")
write.csv(short,"short.csv")
```

```{r VarImp}
# Here we create a data partition in order to make training and test sets from the full data set
cut <- createDataPartition(df$Yards, p=0.8, list = FALSE)
train <- df[cut,]
test <- df[-cut,]
# We start with a basic random forest using only information about the player's location and motion
rf0 <- randomForest(Yards ~ Team + X + Y + S + A + Dis + Orientation + Dir, data=train,mtry=6,importance=TRUE) 
varImp(rf0)
varImpPlot(rf0,type=2)

pred1 <-predict(rf0,newdata=test) 
guess <- abs(mean(test$Yards) - test$Yards)
diff <- abs(pred1 - test$Yards)
mean(diff)

pred <- train(Yards~.,data=train,method='rf',metric=metric,
                    tuneGrid=tunegrid,trControl=control)

rf1 <- randomForest(train[,-c(31,40:46)],train$Yards,
                     sampsize=round(0.6*length(train[,31])),
                     ntree=500,mtry=sqrt(16),importance=TRUE)
## rf0 <- randomForest(Yards ~ Team + X + Y + S + A + Dis + Orientation + Dir, data=short,mtry=6,importance=TRUE) 
## rf0short <- randomForest(Cat ~ Team + X + Y + S + A + Dis + Orientation + Dir, data=short,mtry=6,importance=TRUE) 
```


```{r Feature Engineering}
str(train)
result<-lm(Yards~ Team+X+Y+S+A+Dis+Orientation+Dir+Season+YardLine+Quarter+Down+Distance+FieldPosition+HomeScoreBeforePlay+VisitorScoreBeforePlay+DefendersInTheBox +PlayerWeight+ HomeTeamAbbr +VisitorTeamAbbr +Week+Temperature+Humidity, data= train)
summary(result)
plot(result)
```




